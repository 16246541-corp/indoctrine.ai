# Agent Indoctrination â€“ AI Safety, Bias & Compliance Testing Framework ğŸš€
## PyPI : https://pypi.org/project/agent_indoctrination/
> **Your oneâ€‘stop, openâ€‘source solution for rigorous AI agent evaluation** â€“ from promptâ€‘injection attacks to EU AI Act compliance, with a **Decolonization Score** that quantifies Westernâ€‘ce[...]

---


---

## ğŸ›¡ï¸ Core Value Proposition
- **Comprehensive 3â€‘Layer Testing** â€“ Attack, Truth, Governance (EU AI Act, NIST AI RMF, GDPR, SOC2, ISOâ€¯42001).
- **Automated, Productionâ€‘Ready Reports** â€“ PDF, JSON, Markdown with visual dashboards, 3â€‘D embedding failure maps, and a **Decolonization Score**.
- **CI/CD Friendly** â€“ Seamlessly integrate into GitHub Actions, GitLab CI, Azure Pipelines.
- **Zeroâ€‘Trust, Offlineâ€‘First** â€“ Runs locally, preserving data privacy.
- **Extensible SDK** â€“ Plugâ€‘in custom attacks, policies, and compliance frameworks.

---

## âœ¨ Key Features 
- **ğŸ” Attack Layer** â€“ Detects prompt injection, jailbreak, tokenâ€‘smuggling, multiâ€‘turn Crescendo, and custom adversarial attacks. Scores vulnerabilities with CVSSâ€‘like metrics.
- **âœ… Truth Layer** â€“ Groundedness, consistency, hallucination detection, **Contextâ€‘Adherence Score**, and 3â€‘D embedding visualisation of failure clusters.
- **âš–ï¸ Governance Layer** â€“ Full EU AI Act coverage (Articlesâ€¯9â€‘15â€¯&â€¯52), NIST AI RMF, GDPR, SOC2, ISOâ€¯42001, plus a **Custom Policy Engine**.
- **ğŸŒ Colonization Layer** â€“ 5â€‘dimensional decolonial bias testing (Epistemic, Linguistic, Historical, Cultural, Stereotyping) with a **Decolonization Score** (0â€‘100).
- **ğŸ“Š Benchmark Suite** â€“ 7â€‘dimensional ethical benchmark (Safety, Fairness, Robustness, Transparency, Privacy, Accountability, Truthfulness) plus Values Alignment.
- **ğŸ§© Plugâ€‘andâ€‘Play SDK** â€“ Simple Python API, CLI (`indoctrinate`), and Nyancat rainbow progress UI.
- **ğŸš€ CI/CD Integration** â€“ Readyâ€‘toâ€‘use GitHub Actions workflow, Docker image, and Helm chart.

---

## ğŸ“¦ Installation
```bash
# Core package
pip install indoctrine-ai

# Optional extras for attack engines (PyRIT, Giskard)
pip install "indoctrine-ai"
```

---

## ğŸ› ï¸ Setup Tutorial
### 1ï¸âƒ£ Installing and Running Ollama
1. **Download Ollama** â€“ Visit https://ollama.com and download the macOS installer.
2. **Install a model** â€“ Open a terminal and run:
   ```bash
   ollama pull llama2:13b
   ```
   (Replace `llama2:13b` with any model you prefer.)
3. **Start the server** â€“ Run:
   ```bash
   ollama serve
   ```
   The server will listen on `http://localhost:11434`.
4. **Verify** â€“ In a new terminal, execute:
   ```bash
   curl http://localhost:11434/api/tags
   ```
   You should see a JSON list of available models.

### 2ï¸âƒ£ Installing and Configuring LM Studio
1. **Download LM Studio** â€“ Get the macOS app from https://lmstudio.ai.
2. **Add a model** â€“ In LM Studio, click **Add Model**, choose **Ollama** as the source, and select the model you pulled earlier.
3. **Set the endpoint** â€“ Ensure the endpoint URL is `http://localhost:11434/v1` (OpenAI compatible).
4. **Test a request** â€“ Use the builtâ€‘in chat UI to send a prompt and confirm a response is returned.

### 3ï¸âƒ£ Connecting Indoctrination to Your LLM
Create a simple configuration file `config.yaml`:
```yaml
llm:
  provider: "ollama"
  endpoint: "http://localhost:11434/v1"
  model: "llama2:13b"
```
The framework will use this endpoint for all test runs.

---

## ğŸš€ Quick Start (30â€‘second demo)
```python
from indoctrine-ai import Indoctrinator
from indoctrine-ai.core import AgentInterface

class MyAgent(AgentInterface):
    def send_message(self, message: str) -> str:
        # Replace with your LLM call â€“ here we just echo
        return "response"

indo = Indoctrinator(config_path="config.yaml")
results = indo.run_full_suite(MyAgent())
indo.generate_report(results, output_path="report.pdf")
print("âœ… Report generated: report.pdf")
```
Run the same flow from the CLI:
```bash
indoctrinate run --config config.yaml --agent my_agent.py
indoctrinate report --input results.json --output report.pdf
```

---

## ğŸ“š Documentation & Resources
- **Full Docs**: https://github.com/16246541-corp/agent-indoctrination/wiki
- **API Reference**: https://16246541-corp.github.io/agent-indoctrination/
- **Tutorial Notebook**: `examples/tutorial.ipynb`
- **Benchmark Dashboard**: `demo_report.pdf` (includes visual heatmaps, 3â€‘D embeddings, and decolonization breakdown).

---

## ğŸ“– Why This Product?
The rapid proliferation of powerful LLMâ€‘driven agents brings unprecedented benefits **and** novel risks. Traditional testing tools focus on isolated model metrics (e.g., perplexity) but ignore the *[...]
- **Promptâ€‘injection attacks** where an adversary manipulates the agentâ€™s internal reasoning.
- **Hallucinations** that propagate through multiâ€‘step workflows, leading to unsafe decisions.
- **Regulatory nonâ€‘compliance** with emerging standards such as the EU AI Act, NIST AI RMF, and GDPR.
- **Cultural bias** where models reinforce Westernâ€‘centric viewpoints, marginalising other perspectives.

**Agent Indoctrination** addresses these gaps by providing a **single, unified framework** that evaluates agents across three orthogonal dimensions:
1. **Attack Surface** â€“ Simulated adversarial prompts, jailbreaks, and tokenâ€‘smuggling.
2. **Truthfulness** â€“ Groundedness, consistency, and contextâ€‘adherence across multiâ€‘turn dialogues.
3. **Governance & Bias** â€“ Automated compliance checks against legal frameworks and a novel **Decolonization Score** that quantifies bias across epistemic, linguistic, historical, cultural, and ster[...]

By surfacing these metrics in a single report, teams can **prioritise remediation**, demonstrate compliance to auditors, and build trust with stakeholders.

---

## ğŸ“Š What Does It Test?
### Attack Layer
- **Prompt Injection** â€“ Inserts malicious instructions into user prompts.
- **Jailbreak Detection** â€“ Attempts to bypass safety guards.
- **Tokenâ€‘Smuggling** â€“ Exploits tokenisation quirks to hide malicious intent.
- **Multiâ€‘Turn Crescendo** â€“ Gradually escalates attacks over a conversation.
- **Custom Adversarial Scenarios** â€“ Users can plugâ€‘in their own attack scripts.

### Truth Layer
- **Groundedness** â€“ Checks if responses are supported by supplied knowledge bases.
- **Consistency** â€“ Verifies that the agent gives the same answer to semantically equivalent queries.
- **Hallucination Detection** â€“ Flags statements not present in any reference data.
- **Contextâ€‘Adherence** â€“ Measures how well the agent stays within the provided context.
- **3â€‘D Embedding Failure Maps** â€“ Visualises clusters of erroneous responses.

### Governance Layer
- **EU AI Act** â€“ Automated checks for Articlesâ€¯9â€‘15â€¯&â€¯52 compliance.
- **NIST AI RMF** â€“ Maps test results to the NIST risk management framework.
- **GDPR, SOC2, ISOâ€¯42001** â€“ Verifies dataâ€‘handling and security controls.
- **Custom Policy Engine** â€“ Allows organisations to encode internal policies.

### Colonization Layer (Bias Testing)
- **Epistemic Bias** â€“ Overâ€‘reliance on Western knowledge sources.
- **Linguistic Bias** â€“ Preference for Englishâ€‘centric phrasing.
- **Historical Bias** â€“ Skewed representation of nonâ€‘Western events.
- **Cultural Bias** â€“ Assumptions about norms and values.
- **Stereotyping** â€“ Propagation of harmful stereotypes.
The **Decolonization Score** aggregates these dimensions into a 0â€‘100 rating, where higher scores indicate lower bias.

---

## ğŸ› ï¸ Extending the Framework
### Custom Attack
```python
from agent_indoctrination.engines.attack import BaseAttack

class MyAttack(BaseAttack):
    def execute(self, agent):
        # Your logic here
        return []

indo.register_attack("my_attack", MyAttack())
```
### Custom Compliance
```python
from agent_indoctrination.engines.governance import ComplianceFramework

class MyFramework(ComplianceFramework):
    def check_compliance(self, agent, results):
        # Your checks
        return []

indo.register_framework("my_framework", MyFramework())
```

---

## ğŸ“‚ Repository Structure (SEOâ€‘Friendly)
```
agent_indoctrination/
â”œâ”€ engines/          # attack, truth, governance, values, colonization
â”œâ”€ core/             # AgentInterface, logger, utils
â”œâ”€ reporting/        # PDF/JSON/Markdown generators
â”œâ”€ examples/         # quickstart, custom agents, tutorials
â”œâ”€ docs/             # detailed user guide & API docs
â”œâ”€ tests/            # unit & integration tests (coverage > 90%)
â””â”€ pyproject.toml    # build & dependencies
```

---

## ğŸ¤ Contributing & Community (Boost SEO for "open source AI safety")
We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.
- **Report bugs** â€“ GitHub Issues
- **Suggest features** â€“ Discussions
- **Submit PRs** â€“ Follow the `dev` branch workflow
- **Star the repo** â€“ Increases visibility for AI safety tooling.

---

## ğŸ“„ License
MIT License â€“ see [LICENSE](LICENSE).

---

## ğŸ“ Contact & Support
- **GitHub Issues**: https://github.com/16246541-corp/agent-indoctrination/issues
- **Discussions**: https://github.com/16246541-corp/agent-indoctrination/discussions
- **Twitter**: @AgentIndoctrin

---


**Made with â¤ï¸ for safer, unbiased, and compliant AI**

> **Your oneâ€‘stop, openâ€‘source solution for rigorous AI agent evaluation** â€“ from promptâ€‘injection attacks to EU AI Act compliance, with a **Decolonization Score** that quantifies Westernâ€‘ce[...]

---

## ï¿½ğŸ›¡ï¸ Core Value Proposition
- **Comprehensive 3â€‘Layer Testing** â€“ Attack, Truth, Governance (EU AI Act, NIST AI RMF, GDPR, SOC2, ISOâ€¯42001).
- **Automated, Productionâ€‘Ready Reports** â€“ PDF, JSON, Markdown with visual dashboards, 3â€‘D embedding failure maps, and a **Decolonization Score**.
- **CI/CD Friendly** â€“ Seamlessly integrate into GitHub Actions, GitLab CI, Azure Pipelines.
- **Zeroâ€‘Trust, Offlineâ€‘First** â€“ Runs locally, preserving data privacy.
- **Extensible SDK** â€“ Plugâ€‘in custom attacks, policies, and compliance frameworks.

---

## âœ¨ Key Features (SEOâ€‘Optimized)
- **ğŸ” Attack Layer** â€“ Detects prompt injection, jailbreak, tokenâ€‘smuggling, multiâ€‘turn Crescendo, and custom adversarial attacks. Scores vulnerabilities with CVSSâ€‘like metrics.
- **âœ… Truth Layer** â€“ Groundedness, consistency, hallucination detection, **Contextâ€‘Adherence Score**, and 3â€‘D embedding visualisation of failure clusters.
- **âš–ï¸ Governance Layer** â€“ Full EU AI Act coverage (Articlesâ€¯9â€‘15â€¯&â€¯52), NIST AI RMF, GDPR, SOC2, ISOâ€¯42001, plus a **Custom Policy Engine**.
- **ğŸŒ Colonization Layer** â€“ 5â€‘dimensional decolonial bias testing (Epistemic, Linguistic, Historical, Cultural, Stereotyping) with a **Decolonization Score** (0â€‘100).
- **ğŸ“Š Benchmark Suite** â€“ 7â€‘dimensional ethical benchmark (Safety, Fairness, Robustness, Transparency, Privacy, Accountability, Truthfulness) plus Values Alignment.
- **ğŸ§© Plugâ€‘andâ€‘Play SDK** â€“ Simple Python API, CLI (`indoctrinate`), and Nyancat rainbow progress UI.
- **ğŸš€ CI/CD Integration** â€“ Readyâ€‘toâ€‘use GitHub Actions workflow, Docker image, and Helm chart.

---

## ğŸ“¦ Installation
```bash
# Core package
pip install agent_indoctrination

# Optional extras for attack engines (PyRIT, Giskard)
pip install "agent_indoctrination[attack]"
```

---

## ğŸš€ Quick Start (30â€‘second demo)
```python
from agent_indoctrination import Indoctrinator
from agent_indoctrination.core import AgentInterface

class MyAgent(AgentInterface):
    def send_message(self, message: str) -> str:
        # Replace with your LLM call
        return "response"

indo = Indoctrinator(config_path="config.yaml")
results = indo.run_full_suite(MyAgent())
indo.generate_report(results, output_path="report.pdf")
print("âœ… Report generated: report.pdf")
```

Run the same flow from the CLI:
```bash
indoctrinate run --config config.yaml --agent my_agent.py
indoctrinate report --input results.json --output report.pdf
```

---

## ğŸ“š Documentation & Resources
- **Full Docs**: https://github.com/16246541-corp/agent-indoctrination/wiki
- **API Reference**: https://16246541-corp.github.io/agent-indoctrination/
- **Tutorial Notebook**: `examples/tutorial.ipynb`
- **Benchmark Dashboard**: `demo_report.pdf` (includes visual heatmaps, 3â€‘D embeddings, and decolonization breakdown).

---

## ğŸ¯ Use Cases (Targeted Search Intent)
| Useâ€‘Case | Search Intent | How the Framework Helps |
|----------|---------------|--------------------------|
| **Redâ€‘Team LLMs** | `llm red teaming` | Automated attack suite with CVSS scoring. |
| **Regulatory Audits** | `eu ai act compliance tool` | Endâ€‘toâ€‘end EU AI Act checks (Articlesâ€¯9â€‘15â€¯&â€¯52). |
| **Bias & Fairness Review** | `ai bias detection library` | Multiâ€‘dimensional bias tests + decolonization score. |
| **Model Truthfulness** | `ai truthfulness evaluation` | Groundedness, consistency, hallucination, contextâ€‘adherence. |
| **Enterprise CI/CD** | `ai safety testing ci cd` | GitHub Actions workflow, Docker image, Helm chart. |

---

## ğŸ› ï¸ Extending the Framework
### Custom Attack
```python
from agent_indoctrination.engines.attack import BaseAttack

class MyAttack(BaseAttack):
    def execute(self, agent):
        # Your logic here
        return []

indo.register_attack("my_attack", MyAttack())
```
### Custom Compliance
```python
from agent_indoctrination.engines.governance import ComplianceFramework

class MyFramework(ComplianceFramework):
    def check_compliance(self, agent, results):
        # Your checks
        return []

indo.register_framework("my_framework", MyFramework())
```

---

## ğŸ“‚ Repository Structure 
```
agent_indoctrination/
â”œâ”€ engines/          # attack, truth, governance, values, colonization
â”œâ”€ core/             # AgentInterface, logger, utils
â”œâ”€ reporting/        # PDF/JSON/Markdown generators
â”œâ”€ examples/         # quickstart, custom agents, tutorials
â”œâ”€ docs/             # detailed user guide & API docs
â”œâ”€ tests/            # unit & integration tests (coverage > 90%)
â””â”€ pyproject.toml    # build & dependencies
```

---

## ğŸ¤ Contributing & Community (Boost SEO for "open source AI safety")
We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.
- **Report bugs** â€“ GitHub Issues
- **Suggest features** â€“ Discussions
- **Submit PRs** â€“ Follow the `dev` branch workflow
- **Star the repo** â€“ Increases visibility for AI safety tooling.

---

## ğŸ“„ License
MIT License â€“ see [LICENSE](LICENSE).

---

## ğŸ“ Contact & Support
- **GitHub Issues**: https://github.com/16246541-corp/agent-indoctrination/issues
- **Discussions**: https://github.com/16246541-corp/agent-indoctrination/discussions

---


**Made with â¤ï¸ for safer, unbiased, and compliant AI**
